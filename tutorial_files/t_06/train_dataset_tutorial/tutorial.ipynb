{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BuRNN tutorial: Preparing of the training dataset and NN model training\n",
    "\n",
    "In this tutorial we will use Methanol in water as a model system. In context of BuRNN, we will have Methanol in the inner region and two solvation shells of water molecules will be the buffer region. The rest of the box will be the outer region. The tutorial will be focused on the training dataset generation and the neural network (NN) model training.\n",
    "## Training dataset preparation\n",
    "Starting point for generating of the database of the QM structures for NN model training are snapshots from MD simulation, as was described in the original paper. QM region of the system (inner + buffer region) is extracted by GROMOS program filter from every saved snapshot of the initial MD simulation. Filter program produces one output file which contains cooradinates of all extracted QM regions (for all the snapshots). With this file we start in this tutorial. Firstly, we will extract the coorordinates of individual QM regions into separated GROMOS cnf files (one file per snapshot). Then we will have everythink prepared for QM calculations.\n",
    "\n",
    "We will use semi-empirical program [MOPAC](http://openmopac.net/manual/index.html) for QM calculations in this tutorial. In real practise the choice of the QM software is done by the user. However, automation of QM calculations is necessary to prepare training dataset in the reasonable time. In our case we will use in-house made python modules gromos and mopac (Do not confound with original programs [GROMOS](https://www.gromos.net/) and [MOPAC](http://openmopac.net/manual/index.html)) for such an automation.\n",
    "\n",
    "QM calculations for all the snapshots generated by MD can take some time. Therefore, in this tutorial, we will perform QM calculations only for two MD snapshots to show the training dataset preparation procedure. In the end we will provide you models trained on our complete dataset for running the BuRNN simulation in the next step of the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-house written modules for MOPAC QM calculations automation.\n",
    "import mopac\n",
    "import gromos\n",
    "import additional_spk_utils\n",
    "\n",
    "# standard python modules\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() # current working directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in our tutorial is to separate QM regions of the intial MD snapshots (from filter_output_example.cnf) into individual cnf files. Class gromos.Extract_Buffer_Pls_Inner is used to do it. Resulting cnf files will be stored in buffer_pls_inner_region_configurations directory. The files will contain coordinates of the QM regions for individual MD snapshots (produced by GROMOS program filter).\n",
    "\n",
    "The class gromos.Extract_Buffer_Pls_Inner takes the tuple of GROMOS filter output files (in our case it will have only one item, filter_output_example.cnf) as an argument and by calling method extract() QM regions are separated into individual cnf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_output_path = os.path.join('.', 'filter_output_example.cnf')\n",
    "gromos.Extract_Buffer_Pls_Inner(filtered_cnfs=(filter_output_path,)).extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./buffer_pls_inner_region_configurations/buffer_pls_inner_00000.cnf',\n",
       " './buffer_pls_inner_region_configurations/buffer_pls_inner_00001.cnf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of individual cnf files\n",
    "cnf_files_path = os.path.join('.', 'buffer_pls_inner_region_configurations')\n",
    "cnf_files = sorted(glob(os.path.join(cnf_files_path, '*.cnf')))\n",
    "cnf_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created two separated cnf files (for two MD snapshots) in the previous step. The files contain QM regions (inner + buffer regions) coordinates for the given snapshots. Now we are ready for QM calculations. We have to consider that configurations (snapshots) calculated by MD are probably not the ideal ones from the point of view of QM chemistry. Thus QM energy minimization should be perform to reach more favoured conformations. Moreover, one has to consider that training dataset should represent sufficient part of the conformational space of the given system. Therefore we will include all the energy minimization steps into the training dataset.\n",
    "\n",
    "We will use mopac.Mopac_Minimization_Calculation class for the automation of MOPAC energy minimization. The class takes the list of paths to the cnf files as an argument (cnf_files). User can also specify whether buffer region should be minimized as well (argument freeze_buffer, in our case false -> buffer region will be minimized). MOPAC minimization will be performed for all the snapshots in the cnf_files argument. The results will be stored in MOPAC_results/buffer_pls_inner/aux_out directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the program will remove the previously created folder MOPAC_results (if exists). \n",
    "#It is recommended to rename the previously created folder if you would like to save the previous results.\n",
    "mopac.Mopac_Minimization_Calculation(cnf_files, freeze_buffer=False).run_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/pool/radekc/CD_lab_project/gromos_tutorial/gromos_tutorial_livecoms/tutorial_files/t_06/train_dataset_tutorial/MOPAC_results/buffer_pls_inner/aux_out/buffer_pls_inner_00000.aux',\n",
       " '/pool/radekc/CD_lab_project/gromos_tutorial/gromos_tutorial_livecoms/tutorial_files/t_06/train_dataset_tutorial/MOPAC_results/buffer_pls_inner/aux_out/buffer_pls_inner_00001.aux']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of the MOPAC output files (aux files)\n",
    "aux_files = sorted(glob(os.path.join(cwd, 'MOPAC_results', 'buffer_pls_inner', 'aux_out', '*.aux')))\n",
    "aux_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have produced 2 MOPAC minimization output files in the previous step. Now we have to run the single point (SP) MOPAC calculation for every minimization step. Moreover, in BuRNN approach we predict interaction energies between inner and buffer regions (see original paper for details). Thus, we have to extract individual minimization steps from the output files and then run SP calculation for the inner + buffer region (the whole QM region) and for buffer region separately. \n",
    "This is handled by mopac.Mopac_1scf_Calculation_Aux_In class which takes the following arguments:\n",
    "- aux_files = list of paths to the MOPAC minimization output files\n",
    "- inner_region_size = number of atoms in the inner region (it is used to extract the buffer region for the separate SP calculation)\n",
    "\n",
    "Besides that proper geometry of SPC water molecules has to be preserved for the following BuRNN simulation in GROMOS. This step is included in \n",
    "mopac.Mopac_1scf_Calculation_Aux_In class (it is done by gromos.ReShake class). It requires additional arguments:\n",
    "- topo_path = path to the topology file of the given system\n",
    "- gromos_bin = path to the GROMOS md program\n",
    "- imd_example = path to the initial imd file (will be modified during the process)\n",
    "- mk_example = path to the initial mk_script arg file (will be modified during the process)\n",
    "- mk_lib = path to the mk_script library\n",
    "\n",
    "The output of the Mopac_1scf_Calculation_Aux_In class will be two SP MOPAC calculation files for every minimization step (one file for the inner + buffer region, one for buffer region separately). The output files will be stored in:\n",
    "- MOPAC_results/minimization/buffer_pls_inner/aux_out for inner + buffer regions\n",
    "- MOPAC_results/minimization/buffer/aux_out for buffer regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP mopac calculations with reshake of water molecules\n",
    "# NOTE: the program will remove the previously created folder MOPAC_results/minimization (if exists). \n",
    "#It is recommended to rename the previously created folder if you would like to save the previous results.\n",
    "imd = os.path.join('/','home', 'radekc', 'input_examples', 'reshake', 'reshake.imd')\n",
    "mk_script_example = os.path.join('/', 'home', 'radekc', 'input_examples', 'reshake', 'mk_reshake.arg')\n",
    "lib = os.path.join('/', 'home', 'radekc', 'GROMOS', 'mk_script_libs', 'mk_script_spk_local.lib')\n",
    "gromos_bin = os.path.join('/', 'home', 'radekc', 'GROMOS', 'GROMOS', 'gromosXX', 'gromosXX','BUILD', 'bin', 'md') \n",
    "mopac.Mopac_1scf_Calculation_Aux_In(aux_files, \n",
    "                                    inner_region_size=6, \n",
    "                                    topo_path='../../../../../topo/meoh_54a7.top',\n",
    "                                    gromos_bin=gromos_bin,\n",
    "                                    imd_example=imd,\n",
    "                                    mk_example=mk_script_example,\n",
    "                                    mk_lib=lib).run_calculation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finished QM calculations in previous step. Note that by MOPAC energy minimization we increased the size of the dataset from 2 to 860. It demonstrates the potential of energy minimization to significantly incerase the size of training dataset. On the other hand we have to consider that energy minimization can produce a lot of very similar structures, especially in the end of the minimization process. The latter means that clustering of the training structures can be recommended before the model training (see original paper).\n",
    "In the following part of the tutorial we will build ASE database from our training snapshots, then the database will be used for NN model training. For that purpose we will use another in-house made module additional_spk_utils. Firstly, we will need additional_spk_utils.Build_AseDb_From_Mopac_Aux class to create an ASE database. The class takes the following arguments:\n",
    "- complex_path = path to the mopac output files with the whole QM regions (inner + buffer regions, in our case MOPAC_results/minimization/buffer_pls_inner/aux_out)\n",
    "- buffer_path = path to the mopac output files with the buffer regions (in our case MOPAC_results/minimization/buffer/aux_out)\n",
    "- inner_region_size = number of atoms in the inner region\n",
    "- db_name = name of the resulting ASE dataset\n",
    "- db_properties = the properties which will be stored in the database (in our case: complex energy, buffer energy, energy, forces)\n",
    "- metadata = metadata\n",
    "- reference_energies = reference energies (energies in vacuum) for all the components in the QM region.\n",
    "\n",
    "Here it is good time to describe the last argument reference_energies more in detail. As was mentioned above, in the BuRNN approach we use NN model to predict interaction energy between inner and buffer region in stead of the absolute energy difference (see original paper for more details). The reference energies are used to calculate the interaction energy. Now consider the example. We have inner + buffer region composed of Methanol (inner region) and 15 water molecules (buffer region). Interaction energy is calculate in the following way:\n",
    "- The absolute energies for inner + buffer regions and buffer regions were calculated by MOPAC.\n",
    "- The first number in reference_energies argument coresponds to the energy of Methanol in vacuum, whereas the second represents the energy of one water molecule in vacuum (both were calculated by MOPAC).\n",
    "- Firstly we sum the energies of the individual components of both regions (inner + buffer and buffer) in vacuum.\n",
    "- for our example the summation is done in the following way:\n",
    "    - inner + buffer region = reference energy of Methanol + 15 * reference energy of water molecule\n",
    "    - buffer region = 15 * reference energy of water molecule\n",
    "- The energies calculetad in the previous step are then subtracted from the original energies calculated MOPAC.\n",
    "\n",
    "What we obtain in last step? We obtained the interaction energies. For the inner + buffer region we got the interaction energies between Methanol and between water molecules themselves. In case of buffer region we got interaction energy between water molecules only. By subtracting these two number we obtain the interaction energy between Methanol and water molecules (thus between inner and buffer region). This number is hidden under the name energy in db_properties argument. Similar procedure is done for the forces. The difference is that in the case of forces we are interested in atomic contributions. Therefore normalization of the forces is done by subtracting values for the inner + buffer region and buffer region. The values for the inner region are passed without any subtraction (they are not in the buffer region, so there is nothing to subtract). The subtracted values are hidden behind the name forces in db_properties argument."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class additional_spk_utils.Build_AseDb_From_Mopac_Aux also takes the argument metadata where one can describe the database. It is good to provide key information about the database to make it clear for other users or for you in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of dataset description\n",
    "metadata = {'System' : 'MeOH in water',\n",
    "            'num. of structures' : 860,\n",
    "            'QM software' : 'MOPAC',\n",
    "            'Energy minimization': 'Yes',\n",
    "            'clustering' : 'No',\n",
    "            'Energy units' : 'kcal/mol',\n",
    "            'Force units' : 'kcal/mol/Angstrom',\n",
    "            'distance units' : 'Angstrom'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building of ASE database\n",
    "# NOTE: the program will remove the previous ASE database of the same name specified in db_name argument\n",
    "additional_spk_utils.Build_AseDb_From_Mopac_Aux(complex_path=os.path.join('.', 'MOPAC_results', 'minimization', 'buffer_pls_inner', 'aux_out'),\n",
    "                                                buffer_path=os.path.join('.', 'MOPAC_results', 'minimization', 'buffer', 'aux_out'),\n",
    "                                                db_name='meoh_trial.db', \n",
    "                                                db_properties=['complex_energy', 'buffer_energy', 'energy', 'forces'], \n",
    "                                                inner_region_size=6, \n",
    "                                                reference_energies=[-48.9383958635117, -57.7996759075731],\n",
    "                                                metadata=metadata).build_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of structures: 860\n",
      "Interaction energy for the first structure: -19.37 kcal/mol\n"
     ]
    }
   ],
   "source": [
    "# to check that the database was created\n",
    "db = additional_spk_utils.Build_AseDb(load_existing_database=True, db_name='meoh_trial.db').create_db()\n",
    "print(f'Number of structures: {len(db)}')\n",
    "print(f'Interaction energy for the first structure: {db.__getitem__(0)[\"energy\"][0]:.2f} kcal/mol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'System': 'MeOH in water',\n",
       " 'num. of structures': 860,\n",
       " 'QM software': 'MOPAC',\n",
       " 'Energy minimization': 'Yes',\n",
       " 'clustering': 'No',\n",
       " 'Energy units': 'kcal/mol',\n",
       " 'Force units': 'kcal/mol/Angstrom',\n",
       " 'distance units': 'Angstrom'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show metadata\n",
    "db.get_metadata()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of the training structures was generated in the previous parts. Now we can proceed to the training of the NN model (machine learned potential). Oue model will be based on the [SchNet](https://pubs.aip.org/aip/jcp/article-abstract/148/24/241722/962591/SchNet-A-deep-learning-architecture-for-molecules?redirectedFrom=fulltext) architecture. For the training of the model we will use [SchNetPack](https://pubs.acs.org/doi/10.1021/acs.jctc.8b00908) package. \n",
    "\n",
    "The [SchNet](https://pubs.aip.org/aip/jcp/article-abstract/148/24/241722/962591/SchNet-A-deep-learning-architecture-for-molecules?redirectedFrom=fulltext) model is a convolutional neural network (CNN) with a continuous filter. It is very similar to the common CNNs used in image recognition, for instance. In contrast to the images, molecules cannot be described by the discrete matrix of pixels and thus the continuous filter is applied instead of a discrete one. The SchNet model is composed of two NNs. The main one is responsible for the prediction of the given property itself (input is the vector of atomic numbers for the given structure). The second one generates the filter for the convolution (input: positions of the individual atoms of the given structure). The main NN is divided into three main blocks. The first is the embedding layer which creates the feature vectors for the individual atoms within the structure (therefore the whole structure is represented by the 2D matrix of shape(number of atom-wise features, number of atoms)). The second part of the model is the series of the interaction blocks. One interaction block contains one convolutional layer. This block is responsible for creating the representation of the system. The last part is the output module which predicts the given property of the structure (in our case energy). If you are interested in SchNet architecture in more detail see original [paper](https://pubs.aip.org/aip/jcp/article-abstract/148/24/241722/962591/SchNet-A-deep-learning-architecture-for-molecules?redirectedFrom=fulltext).\n",
    "\n",
    "In practice, the SchNet model can be trained using python script spk_run.py provided with the SchNetPack package. Here we will use an additional bash script train.sh (is already prepared for you) to do so. The script will run spk_run.py with the specified arguments. spk_run.py takes the following arguments:\n",
    "- positional arguments:\n",
    "    - mode: str=train\n",
    "    - architecture: str=schnet\n",
    "    - dataset: str=custom \n",
    "    - datapath: str, path to the ASE database\n",
    "    - modelpath: str, path to the model to be created\n",
    "- optional arguments:\n",
    "    - --help\n",
    "    - --cuda = use Nvidia GPU for training\n",
    "    - --parallel = parallel training on more GPUs\n",
    "    - --seed = random seed for torch and numpy\n",
    "    - --overwrite = remove previous model directory\n",
    "    - --split_path = path to your own npz file with data split\n",
    "    - --split = train, validation split; the rest of the dataset is used for testing\n",
    "    - --max_epochs = maximum number of training epochs (default 5000)\n",
    "    - --max_steps = maximum number of training steps (default None)\n",
    "    - --lr = learning rate (default 0.0001)\n",
    "    - --lr_decay = learning rate decay (default 0.8)\n",
    "    - --lr_min = minimal learning rate (default 1e-06)\n",
    "    - --lr_patience = epochs without improvement before reducing the learning rate (default 25)\n",
    "    - --logger = logger (default csv)\n",
    "    - --log_every_n_epochs = log metrics every given number of epochs (default 1)\n",
    "    - --check_point_interval = store checkpoint every n epochs (default 1)\n",
    "    - --keep_n_checkpoints = number of checkpoints that will be stored (default 3)\n",
    "    - --environment_provider_device = It is recommended to use CPU (default cpu)\n",
    "    - --features = number of atomwise features (default 128)\n",
    "    - --interactions = number of interaction blocks (default 3)\n",
    "    - --cutoff_function = default cosine\n",
    "    - --num_gaussians = number of gaussians to expand distances (default 50)\n",
    "    - --normalize_filter = normalize convolution filters by number of neighbors\n",
    "    - --property = property to be predicted (default energy)\n",
    "    - --cutoff = cutoff (default 10.0)\n",
    "    - --batch_size = batch size (default 100)\n",
    "    - --environment_provider = environment provider for the dataset (default simple)\n",
    "    - --derivative = derivative of the property to be predicted (default None)\n",
    "    - --negative_dr = multiply derivatives by -1 for training (when forces are provided instead of gradients, default False)\n",
    "    - --force = name of force property in the dataset (alias for the derivative + negative_dr, default None)\n",
    "    - --contributions = contributions of dataset property to be predicted (default None)\n",
    "    - --stress = train on stress tensor if not None (default None)\n",
    "    - --aggregation_mode = mode for aggregating atomix properties (default sum)\n",
    "    - --output_module = select output module for the selected property (default atomwise)\n",
    "    - --rho = tradeoff weights between property and derivative (default {})\n",
    "\n",
    "In our case, we will train only a small model as an example of the model training process in SchNetPack. The complete models for the BuRNN simulation are provided in the directory \"models\". In our example, we will use our database (argument datapath). We need to specify in which directory the resulting model will be stored (argument modelpath). The training dataset has to be split into the training, validation and testing parts. In our case, we will use a random split (80 % training, 10 % validation and 10 % testing data). The sizes of training and validation data are specified in the argument split, respectively. The rest of the dataset is used for the final testing of the model. The model will be trained for 2 training epochs. we will use 32 atom-wise features and 1 interaction block to obtain a very small model which will be trained very quickly. Specify the necesseary arguments in the train.sh script and run it from the command line. The resulting model will be stored in the specified directory. Moreover, the directory contains log file (log.csv) and the file with the arguments used for the model training (args.json). The script will also run the spk_run.py in evaluation mode. The result of the evaluation will be stored in the model directory (evaluation.txt file). The evaluation will be done on the test data.\n",
    "\n",
    "The hardest part of the model training process is the proper selection of the training hyperparameters. In practice, it is usually done by trial/error approach (at least partially). The general recommendation is to start with the default values of the SchNet architecture. If the resulting model does not fulfill your requirements, you can try to modify the individual hyperparameters. The hyperparameters number of atom-wise features (features) and number of interactions blocks (interactions) are the most important ones. These hyperparameters define the number of parameters of the model and thus its complexity. Therefore, one should start with modifying of those hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spk_py30912",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
